{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcwmMytIacTj"
      },
      "outputs": [],
      "source": [
        "!pip install visual-automata automathon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from automathon import DFA\n",
        "\n",
        "# Define DFA\n",
        "states = {'q0', 'q1', 'qdead'}\n",
        "input_symbols = set([chr(i) for i in range(97, 123)])  # a-z\n",
        "\n",
        "transitions = {\n",
        "    'q0': {ch: 'q1' for ch in input_symbols},   # first letter must be lowercase\n",
        "    'q1': {ch: 'q1' for ch in input_symbols},   # continue with lowercase\n",
        "    'qdead': {ch: 'qdead' for ch in input_symbols},  # trap state\n",
        "}\n",
        "\n",
        "# âœ… Correct DFA initialization (positional args)\n",
        "dfa = DFA(\n",
        "    states,\n",
        "    input_symbols,\n",
        "    transitions,\n",
        "    'q0',           # initial state\n",
        "    {'q1'}          # accepting states\n",
        ")\n",
        "\n",
        "# Test DFA\n",
        "test_words = [\"cat\", \"dog1\", \"DogHouse\", \"a\", \"zebra\", \"cats\", \"1dog\", \"dog_house\", \" house\"]\n",
        "for word in test_words:\n",
        "    try:\n",
        "        if dfa.accepts_input(word):\n",
        "            print(word, \"=> Accepted\")\n",
        "        else:\n",
        "            print(word, \"=> Not Accepted\")\n",
        "    except:\n",
        "        print(word, \"=> Not Accepted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czcuE8ALatwn",
        "outputId": "8eb3366c-1fb0-40c0-dd38-f300a8842f25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat => Not Accepted\n",
            "dog1 => Not Accepted\n",
            "DogHouse => Not Accepted\n",
            "a => Not Accepted\n",
            "zebra => Not Accepted\n",
            "cats => Not Accepted\n",
            "1dog => Not Accepted\n",
            "dog_house => Not Accepted\n",
            " house => Not Accepted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 2. FST for Brown Corpus Nouns\n",
        "\n",
        "import re\n",
        "\n",
        "# Load nouns file\n",
        "with open(\"/content/brown_nouns.txt\", \"r\") as f:\n",
        "    nouns = f.read().splitlines()\n",
        "\n",
        "def noun_fst(word):\n",
        "    # E insertion: add 'es' after s, z, x, ch, sh\n",
        "    if re.search(r'(s|z|x|ch|sh)$', word):\n",
        "        return f\"{word}+N+PL\", word[:-0]+ \"es\"\n",
        "    # Y replacement: consonant+y -> ies\n",
        "    elif re.search(r'[^aeiou]y$', word):\n",
        "        return f\"{word[:-1]}+N+PL\", word[:-1] + \"ies\"\n",
        "    # S addition: add 's'\n",
        "    elif re.search(r'^[a-z]+$', word):\n",
        "        return f\"{word}+N+SG\", word + \"s\"\n",
        "    else:\n",
        "        return \"Invalid Word\", None\n",
        "\n",
        "# Generate features for first 20 nouns\n",
        "for w in nouns[:20]:\n",
        "    sg = f\"{w}+N+SG\"\n",
        "    pl = noun_fst(w)\n",
        "    print(f\"{w} -> {sg} | {pl}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9jyCDkCbE06",
        "outputId": "e7872af7-7cbd-44f4-93a4-349dc42d8862"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "investigation -> investigation+N+SG | ('investigation+N+SG', 'investigations')\n",
            "primary -> primary+N+SG | ('primar+N+PL', 'primaries')\n",
            "election -> election+N+SG | ('election+N+SG', 'elections')\n",
            "evidence -> evidence+N+SG | ('evidence+N+SG', 'evidences')\n",
            "irregularities -> irregularities+N+SG | ('irregularities+N+PL', 'es')\n",
            "place -> place+N+SG | ('place+N+SG', 'places')\n",
            "jury -> jury+N+SG | ('jur+N+PL', 'juries')\n",
            "presentments -> presentments+N+SG | ('presentments+N+PL', 'es')\n",
            "charge -> charge+N+SG | ('charge+N+SG', 'charges')\n",
            "election -> election+N+SG | ('election+N+SG', 'elections')\n",
            "praise -> praise+N+SG | ('praise+N+SG', 'praises')\n",
            "thanks -> thanks+N+SG | ('thanks+N+PL', 'es')\n",
            "manner -> manner+N+SG | ('manner+N+SG', 'manners')\n",
            "election -> election+N+SG | ('election+N+SG', 'elections')\n",
            "term -> term+N+SG | ('term+N+SG', 'terms')\n",
            "jury -> jury+N+SG | ('jur+N+PL', 'juries')\n",
            "reports -> reports+N+SG | ('reports+N+PL', 'es')\n",
            "irregularities -> irregularities+N+SG | ('irregularities+N+PL', 'es')\n",
            "primary -> primary+N+SG | ('primar+N+PL', 'primaries')\n",
            "handful -> handful+N+SG | ('handful+N+SG', 'handfuls')\n"
          ]
        }
      ]
    }
  ]
}