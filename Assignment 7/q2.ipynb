{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a5f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7219bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../ass5/train.csv')\n",
    "val_df = pd.read_csv('../ass5/validation.csv')\n",
    "test_df = pd.read_csv('../ass5/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c99d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: ['યુનાઇટેડ સ્ટેટ્સ બ્યુરો ઓફ લેબર સ્ટેટિસ્ટિક્સ અનુસાર, 2008 માં અપરાધ દ્રશ્ય તપાસકર્તાઓ માટેનો સરેરાશ પગાર $ 55,040 હતો, અથવા કલાક દીઠ 23.97 ડોલર હતો', 'શ્રદ્ધાએ શરૂઆતમાં સારી રમત બતાવી, પરંતુ પછી તેની રમત એકદમ ધીમી થઈ ગઈ', 'અને વિચારોને વધુ સ્પષ્ટતા આપવા માટે, સોવલો અને અલજીઝ સાથેના ફટકામાં પ્રકાશની રુન છીણી પર કાપી છે']\n",
      "Validation samples: ['જે ધ્યાને લેતા દેશભરમાં નવીનતમ ટેકનોલોજીનો ઉપયોગ કરીને એકીસાથે ઓછા સમયમાં વધુ પ્રમાણમાં આવાસો બનાવવામાં આવે તેવું કેન્દ્ર સરકાર દ્વારા સુચન કરવામાં આવેલ છે', '11. આ રમત \"સાપની\"', 'એક માદા સ્વપ્ન પુસ્તક એવી સ્ત્રીને પ્રિય પ્રણય રજૂ કરે છે જે વોર્મ્સ ખાવવાનું સ્વપ્ન ધરાવે છે;']\n",
      "Test samples: ['રાત્રીના સમયે એકલ દોકલ વ્યકિત દેખાય તો તેના વાહનને આંતરી છરી બતાવી માલમત્તા લૂંટી લેવાની આદત છે', 'હાલમાં જ આવેલા એક રિપોર્ટમાં આ વાત કહેવામાં આવી છે', 'જલદી કણક જાડા અને એકરૂપ બની જાય છે, વેનીલા એસેન્સમાં રેડવું અને ફરીથી ફરીથી મિશ્રણ કરો']\n"
     ]
    }
   ],
   "source": [
    "def extract_sentences(df, column=\"sentence\"):\n",
    "    \"\"\"Extract plain text sentences from the specified column.\"\"\"\n",
    "    # Drop NaN and strip extra spaces\n",
    "    return df[column].dropna().astype(str).str.strip().tolist()\n",
    "\n",
    "# Extract lists of sentences\n",
    "train_sentences = extract_sentences(train_df)\n",
    "val_sentences   = extract_sentences(val_df)\n",
    "test_sentences  = extract_sentences(test_df)\n",
    "\n",
    "# Optional: print a few samples\n",
    "print(\"Train samples:\", train_sentences[:3])\n",
    "print(\"Validation samples:\", val_sentences[:3])\n",
    "print(\"Test samples:\", test_sentences[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6648fcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence):\n",
    "    \"\"\"\n",
    "    Splits a sentence into words, converts to lowercase, and removes punctuation.\n",
    "    \"\"\"\n",
    "    # Ensure the input is a string\n",
    "    if not isinstance(sentence, str):\n",
    "        return []\n",
    "    tokens = re.sub(r'[^\\w\\s]', '', sentence.lower()).split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1444912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(train_corpus_tokens):\n",
    "    \"\"\"\n",
    "    Calculates IDF scores for a vocabulary learned from the training corpus.\n",
    "    :param train_corpus_tokens: A list of tokenized sentences from the training data.\n",
    "    :return: A tuple containing (vocabulary, idf_scores_dict).\n",
    "    \"\"\"\n",
    "    num_docs = len(train_corpus_tokens)\n",
    "    \n",
    "    # Build vocabulary and document frequency (DF) in one pass\n",
    "    vocab = set()\n",
    "    doc_freq = {}\n",
    "    for doc in train_corpus_tokens:\n",
    "        unique_words_in_doc = set(doc)\n",
    "        for word in unique_words_in_doc:\n",
    "            vocab.add(word)\n",
    "            doc_freq[word] = doc_freq.get(word, 0) + 1\n",
    "            \n",
    "    sorted_vocab = sorted(list(vocab))\n",
    "    \n",
    "    # Calculate IDF scores using the document frequencies\n",
    "    idf_scores = {\n",
    "        word: math.log(num_docs / (doc_freq.get(word, 0) + 1))\n",
    "        for word in sorted_vocab\n",
    "    }\n",
    "    \n",
    "    print(f\"Learned vocabulary with {len(sorted_vocab)} words and calculated IDF scores.\")\n",
    "    return sorted_vocab, idf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87314396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(sentence_tokens):\n",
    "    \"\"\"\n",
    "    Calculates TF scores for a single tokenized sentence.\n",
    "    :param sentence_tokens: A list of words for one sentence.\n",
    "    :return: A dictionary of {word: tf_score}.\n",
    "    \"\"\"\n",
    "    doc_len = len(sentence_tokens)\n",
    "    if doc_len == 0:\n",
    "        return {}\n",
    "        \n",
    "    word_counts = {}\n",
    "    for word in sentence_tokens:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "        \n",
    "    tf_scores = {\n",
    "        word: count / doc_len\n",
    "        for word, count in word_counts.items()\n",
    "    }\n",
    "    return tf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d52e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train = [tokenize(s) for s in train_sentences]\n",
    "tokenized_val = [tokenize(s) for s in val_sentences]\n",
    "tokenized_test = [tokenize(s) for s in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50f2e8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned vocabulary with 5477 words and calculated IDF scores.\n"
     ]
    }
   ],
   "source": [
    "vocabulary, idf_values = compute_idf(tokenized_train)\n",
    "word_to_index = {word: i for i, word in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f2b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Keep all your other functions like tokenize, compute_idf, compute_tf the same)\n",
    "\n",
    "def create_tfidf_vectors(corpus_tokens, vocabulary, idf_scores, word_map):\n",
    "    \"\"\"\n",
    "    Creates a memory-efficient sparse representation of TF-IDF vectors.\n",
    "    Instead of a list of lists, it returns a list of dictionaries.\n",
    "    \"\"\"\n",
    "    tfidf_vector_list = []\n",
    "    \n",
    "    for doc_tokens in corpus_tokens:\n",
    "        tf_scores_doc = compute_tf(doc_tokens)\n",
    "        \n",
    "        # This dictionary will only store non-zero values for this sentence.\n",
    "        sparse_vector = {} \n",
    "        \n",
    "        for word, tf_val in tf_scores_doc.items():\n",
    "            if word in word_map:\n",
    "                index = word_map[word]\n",
    "                # Store the TF-IDF score with its index as the key\n",
    "                sparse_vector[index] = tf_val * idf_scores[word]\n",
    "                \n",
    "        tfidf_vector_list.append(sparse_vector)\n",
    "        \n",
    "    return tfidf_vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "395cd0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectorizing all datasets using a sparse representation...\n",
      "...Done.\n",
      "\n",
      "Sparse Vectorization Summary\n",
      "Number of training vectors: 1238\n",
      "Number of validation vectors: 154\n",
      "Number of testing vectors: 156\n",
      "\n",
      "First sparse vector (train): {3881: 0.27948283794280854, 4813: 0.27948283794280854, 3354: 0.2493460040054196, 931: 0.19810013459926107, 4227: 0.27948283794280854, 4814: 0.27948283794280854, 326: 0.2015802523241974, 40: 0.2618539201989753, 3525: 0.191878358788797, 335: 0.2618539201989753, 2359: 0.2618539201989753, 2155: 0.27948283794280854, 3592: 0.21920917006803067, 5121: 0.2618539201989753, 2708: 0.2493460040054196, 98: 0.27948283794280854, 5294: 0.1391123074245474, 277: 0.16632241683653098, 1239: 0.19810013459926107, 2290: 0.27948283794280854, 57: 0.27948283794280854, 2084: 0.225014882790836}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVectorizing all datasets using a sparse representation...\")\n",
    "X_train_tfidf_sparse = create_tfidf_vectors(tokenized_train, vocabulary, idf_values, word_to_index)\n",
    "X_val_tfidf_sparse = create_tfidf_vectors(tokenized_val, vocabulary, idf_values, word_to_index)\n",
    "X_test_tfidf_sparse = create_tfidf_vectors(tokenized_test, vocabulary, idf_values, word_to_index)\n",
    "print(\"...Done.\")\n",
    "\n",
    "print(\"\\nSparse Vectorization Summary\")\n",
    "print(f\"Number of training vectors: {len(X_train_tfidf_sparse)}\")\n",
    "print(f\"Number of validation vectors: {len(X_val_tfidf_sparse)}\")\n",
    "print(f\"Number of testing vectors: {len(X_test_tfidf_sparse)}\")\n",
    "\n",
    "print(f\"\\nFirst sparse vector (train): {X_train_tfidf_sparse[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
