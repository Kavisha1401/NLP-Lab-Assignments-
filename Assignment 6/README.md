# NLP Assignment 6 тАУ Quadrigram Language Models  

##  Overview  
This assignment implements **Quadrigram (4-gram) Language Models** with two smoothing techniques:  
1. **Katz Backoff**  
2. **KneserтАУNey Smoothing**  

For each model, we generate sentences using:  
- **Greedy decoding** (maximum likelihood)  
- **Beam Search** (beam size = 20)  

The dataset used is `Guj_3000.txt`, which contains Gujarati sentences.  

---

## тЪЩя╕П How to Run  

### 1. Open in Google Colab  
- Upload the notebook (`Assignment6.ipynb`) to **Google Colab**.  
- Upload the dataset file `Guj_3000.txt` in the same Colab session.  

### 2. Install Dependencies  
The only external library required is **NLTK**:  
```bash
!pip install nltk
```

### 3. Run the Notebook Step by Step  
The notebook is divided into sections:  
1. **Setup & Imports** тАУ installs dependencies and loads libraries.  
2. **Load and Preprocess Dataset** тАУ reads `Guj_3000.txt`, tokenizes sentences, and adds start/end tokens.  
3. **Build N-gram Counts** тАУ extracts unigram, bigram, trigram, and quadrigram frequencies.  
4. **Katz Backoff Implementation** тАУ computes backoff probabilities.  
5. **KneserтАУNey Smoothing Implementation** тАУ computes smoothed probabilities.  
6. **Sentence Generation Functions** тАУ implements greedy and beam search decoding.  
7. **Sentence Generation** тАУ generates sample sentences for all models and methods.  

### 4. Outputs  
- The notebook prints generated Gujarati sentences.  
- Example outputs:  
  ```
  ЁЯФ╣ Katz Backoff - Greedy
  ркЧрк╛ркВркзрлАркиркЧрк░ркорк╛ркВ рк╣рк╛рк▓ркорк╛ркВ рк░рк╛ркЬркХрк╛рк░ркг ркХрлНрк╖рлЗркдрлНрк░рлЗ рк╢рк╛рк│рк╛ рк╡рк┐ркХрк╛рк╕ рк╕ркорк┐ркдрк┐ркП рк╕рлНркеркЧрк┐ркд ркеркпрлБркВ
  ркЬрк╛ркоркиркЧрк░ркорк╛ркВ рк╣рк╛рк▓ркорк╛ркВ рк╡рк┐ркЬрлНркЮрк╛рки ркХрлНрк╖рлЗркдрлНрк░рлЗ рк░рк╛ркЬрлНркп рк╕рк░ркХрк╛рк░ркП рк╢рк░рлБ ркХрк░рлНркпрлБркВ
  
  ЁЯФ╣ KneserтАУNey - Beam Search
  рк╕рлБрк░ркдркорк╛ркВ ркЖркЬрлЗ рк╢рк┐ркХрлНрк╖ркг ркХрлНрк╖рлЗркдрлНрк░рлЗ ркФркжрлНркпрлЛркЧрк┐ркХ рк╡рк┐ркХрк╛рк╕ ркирк┐ркЧркоркП ркЦрлБрк▓рк╛рк╕рлЛ ркХрк░рлНркпрлЛ
  ркЬрлВркирк╛ркЧрквркорк╛ркВ ркЖ ркорк╣рк┐ркирлЗ ркХрлНрк░рлАркбрк╛ ркХрлНрк╖рлЗркдрлНрк░рлЗ рк╢рк╛рк│рк╛ рк╡рк┐ркХрк╛рк╕ рк╕ркорк┐ркдрк┐ркП рк╢рк░рлБ ркХрк░рлНркпрлБркВ
  ```
- You can adjust the loop to generate **100 sentences per model**.  

---

## ЁЯУВ Files in this Repository  
- `Assignment6.ipynb` тЖТ Colab notebook with full implementation.  
- `Guj_3000.txt` тЖТ Gujarati dataset (input text).  
- `README.md` тЖТ Instructions and documentation.  

---

## тЬЕ What I Did in This Assignment  
- Preprocessed Gujarati dataset for n-gram modeling.  
- Implemented **Katz Backoff** for quadrigrams.  
- Implemented **KneserтАУNey Smoothing** for quadrigrams.  
- Implemented **Greedy decoding** and **Beam Search (beam size=20)**.  
- Generated sample Gujarati sentences using both models and decoding methods.  


## Author

Assignment completed as part of **NLP Course - Assignment 6**.\
Rollno.: *U23AI016*\
Institute: SVNIT
