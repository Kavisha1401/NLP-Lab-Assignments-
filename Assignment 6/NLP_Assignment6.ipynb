{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pp5KX_pggmv",
        "outputId": "a3801bf8-e4e0-4b03-c71a-6e3b070831a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  1. Imports\n",
        "import nltk\n",
        "from collections import defaultdict, Counter\n",
        "import math, random\n",
        "\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrYLRMGNgiJ0",
        "outputId": "f4d026d1-5f1b-4d2e-d7af-f1eb336cf074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  2. Load and preprocess dataset\n",
        "\n",
        "file_path = \"Guj_3000.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = f.read().splitlines()\n",
        "\n",
        "# Tokenize sentences (Gujarati text is tokenized by spaces)\n",
        "# Tokenize by splitting on spaces (works for Gujarati text)\n",
        "sentences = [sent.split() for sent in data]\n",
        "\n",
        "\n",
        "# Add start <s> and end </s> tokens for quadrigrams\n",
        "processed = []\n",
        "for sent in sentences:\n",
        "    processed.append([\"<s>\", \"<s>\", \"<s>\"] + sent + [\"</s>\"])\n",
        "\n",
        "print(\"Sample sentence tokens:\", processed[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESStdhjngmbB",
        "outputId": "9c28cfb9-d552-4dd3-f490-f2f024732526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample sentence tokens: ['<s>', '<s>', '<s>', '1.', 'ркЧрк╛ркВркзрлАркиркЧрк░ркорк╛ркВ', 'рк╣рк╛рк▓ркорк╛ркВ', 'рк░рк╛ркЬркХрк╛рк░ркг', 'ркХрлНрк╖рлЗркдрлНрк░рлЗ', 'рк╢рк╛рк│рк╛', 'рк╡рк┐ркХрк╛рк╕', 'рк╕ркорк┐ркдрк┐ркП', 'рк╕рлНркеркЧрк┐ркд', 'ркеркпрлБркВ;', 'ркдрлЗ', 'ркЙрккрк░рк╛ркВркд', '88', 'ркорлБркжрлНркжрк╛ркУ', 'рккрк░', 'ркнрк╛рк░', 'ркорлВркХрк╛ркпрлЛ', 'ркЕркирлЗ', 'ркХрк╛рк░рлЛркмрк╛рк░ркорк╛ркВ', 'рк╡рлГркжрлНркзрк┐', 'ркирлЛркВркзрк╛ркИ.', 'рк▓ркХрлНрк╖рлНркпрк╛ркВркХрлЛ', 'ркЖркЧрк╛ркорлА', 'ркЫ', 'ркорк╣рк┐ркирк╛ркорк╛ркВ', 'рккрлВрк░рлНркг', 'ркХрк░рк╡рк╛ркирлЛ', 'ркЙркжрлНркжрлЗрк╢', 'ркЫрлЗ.', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  3. Build N-gram counts (up to 4-gram)\n",
        "from collections import Counter\n",
        "\n",
        "unigrams = Counter()\n",
        "bigrams = Counter()\n",
        "trigrams = Counter()\n",
        "quadrigrams = Counter()\n",
        "\n",
        "for sent in processed:\n",
        "    for i in range(len(sent)):\n",
        "        unigrams[tuple(sent[i:i+1])] += 1\n",
        "        if i < len(sent)-1:\n",
        "            bigrams[tuple(sent[i:i+2])] += 1\n",
        "        if i < len(sent)-2:\n",
        "            trigrams[tuple(sent[i:i+3])] += 1\n",
        "        if i < len(sent)-3:\n",
        "            quadrigrams[tuple(sent[i:i+4])] += 1\n",
        "\n",
        "print(\"Unigrams:\", len(unigrams))\n",
        "print(\"Quadrigrams:\", len(quadrigrams))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEA-pY_FguJI",
        "outputId": "40df0ec9-0083-4c75-cc1b-980e3b0aee36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams: 1370\n",
            "Quadrigrams: 10540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  4. Katz Backoff Implementation\n",
        "\n",
        "# For unseen higher n-grams, fall back to lower n-gram probability.\n",
        "\n",
        "def katz_backoff_prob(ngram, d=0.5):\n",
        "    \"\"\"\n",
        "    Compute Katz backoff probability for a given 4-gram.\n",
        "    \"\"\"\n",
        "    if quadrigrams[ngram] > 0:\n",
        "        return (quadrigrams[ngram] - d) / trigrams[ngram[:-1]]\n",
        "    elif trigrams[ngram[1:]] > 0:\n",
        "        return (trigrams[ngram[1:]] - d) / bigrams[ngram[1:-1]]\n",
        "    elif bigrams[ngram[2:]] > 0:\n",
        "        return (bigrams[ngram[2:]] - d) / unigrams[ngram[2:-1]]\n",
        "    else:\n",
        "        return unigrams[ngram[3:]] / sum(unigrams.values())\n"
      ],
      "metadata": {
        "id": "7Nrle1h3h_D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  5. KneserтАУNey Smoothing Implementation\n",
        "\n",
        "# Discounted continuation probability for unseen n-grams\n",
        "\n",
        "def kneser_ney_prob(ngram, d=0.75):\n",
        "    quad_count = quadrigrams[ngram]\n",
        "    tri_count = trigrams[ngram[:-1]]\n",
        "\n",
        "    if tri_count > 0:\n",
        "        prob = max(quad_count - d, 0) / tri_count\n",
        "        # continuation probability\n",
        "        continuation = len([1 for q in quadrigrams if q[1:] == ngram[1:]]) / len(quadrigrams)\n",
        "        prob += (d / tri_count) * continuation\n",
        "    else:\n",
        "        prob = unigrams[ngram[3:]] / sum(unigrams.values())\n",
        "\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "OMTGFZmniGd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ЁЯУМ 6. Sentence Generation (Greedy + Beam Search)\n",
        "VOCAB = list(set([w for s in processed for w in s]))\n",
        "\n",
        "def generate_sentence(model=\"katz\", max_len=20, method=\"greedy\", beam_size=20):\n",
        "    sent = [\"<s>\", \"<s>\", \"<s>\"]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        candidates = {}\n",
        "        for w in VOCAB:\n",
        "            ngram = tuple(sent[-3:] + [w])\n",
        "            if model == \"katz\":\n",
        "                prob = katz_backoff_prob(ngram)\n",
        "            else:\n",
        "                prob = kneser_ney_prob(ngram)\n",
        "            candidates[w] = prob\n",
        "\n",
        "        if method == \"greedy\":\n",
        "            next_word = max(candidates, key=candidates.get)\n",
        "            sent.append(next_word)\n",
        "            if next_word == \"</s>\":\n",
        "                break\n",
        "\n",
        "        elif method == \"beam\":\n",
        "            # Beam Search\n",
        "            beams = [[sent, 0.0]]\n",
        "            for _ in range(max_len):\n",
        "                new_beams = []\n",
        "                for seq, score in beams:\n",
        "                    for w in VOCAB:\n",
        "                        ngram = tuple(seq[-3:] + [w])\n",
        "                        if model == \"katz\":\n",
        "                            prob = katz_backoff_prob(ngram)\n",
        "                        else:\n",
        "                            prob = kneser_ney_prob(ngram)\n",
        "                        new_beams.append([seq+[w], score+math.log(prob+1e-10)])\n",
        "                # keep top k beams\n",
        "                beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n",
        "                if beams[0][0][-1] == \"</s>\":\n",
        "                    break\n",
        "            sent = beams[0][0]\n",
        "            break\n",
        "    return \" \".join(sent[3:])\n"
      ],
      "metadata": {
        "id": "QpBuAhEriOCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentence(model=\"katz\", max_len=20, method=\"greedy\", beam_size=20, top_k=50):\n",
        "    sent = [\"<s>\", \"<s>\", \"<s>\"]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        candidates = {}\n",
        "        for w in VOCAB:\n",
        "            if w == \"<s>\":\n",
        "                continue\n",
        "            ngram = tuple(sent[-3:] + [w])\n",
        "            if model == \"katz\":\n",
        "                prob = katz_backoff_prob(ngram)\n",
        "            else:\n",
        "                prob = kneser_ney_prob(ngram)\n",
        "            candidates[w] = prob\n",
        "\n",
        "        # keep only top_k candidates\n",
        "        candidates = dict(sorted(candidates.items(), key=lambda x: x[1], reverse=True)[:top_k])\n",
        "\n",
        "        if method == \"greedy\":\n",
        "            next_word = max(candidates, key=candidates.get)\n",
        "            sent.append(next_word)\n",
        "            if next_word == \"</s>\":\n",
        "                break\n",
        "\n",
        "        elif method == \"beam\":\n",
        "            beams = [[sent, 0.0]]\n",
        "            for _ in range(max_len):\n",
        "                new_beams = []\n",
        "                for seq, score in beams:\n",
        "                    for w, prob in candidates.items():  # ЁЯЪА now only top_k words\n",
        "                        new_beams.append([seq+[w], score+math.log(prob+1e-10)])\n",
        "                beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n",
        "                if beams[0][0][-1] == \"</s>\":\n",
        "                    break\n",
        "            sent = beams[0][0]\n",
        "            break\n",
        "    return \" \".join(sent[3:])\n"
      ],
      "metadata": {
        "id": "mRlv5iSwsaYi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ЁЯФ╣ Katz Backoff - Greedy\")\n",
        "for i in range(5):\n",
        "    print(generate_sentence(model=\"katz\", method=\"greedy\"))\n",
        "\n",
        "print(\"\\nЁЯФ╣ Katz Backoff - Beam Search\")\n",
        "for i in range(5):\n",
        "    print(generate_sentence(model=\"katz\", method=\"beam\"))\n",
        "\n",
        "print(\"\\nЁЯФ╣ KneserтАУNey - Greedy\")\n",
        "for i in range(5):\n",
        "    print(generate_sentence(model=\"kn\", method=\"greedy\"))\n",
        "\n",
        "print(\"\\nЁЯФ╣ KneserтАУNey - Beam Search\")\n",
        "for i in range(5):\n",
        "    print(generate_sentence(model=\"kn\", method=\"beam\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl7EhQVasbf_",
        "outputId": "95ef13e0-28c9-4d46-f075-0fad440227ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ЁЯФ╣ Katz Backoff - Greedy\n",
            "рккрк░ ркнрк╛рк░ ркорлВркХрк╛ркпрлЛ ркЕркирлЗ рк╕рлНркерк╛ркирк┐ркХ рк╕рлНркдрк░рлЗ рк╕рк╣ркХрк╛рк░ рк╡ркзрлНркпрлЛ. ркУркирк▓рк╛ркЗрки рккрлЛрк░рлНркЯрк▓ рккркг рк╢рк░рлВ ркХрк░рк╡рк╛ркорк╛ркВ ркЖрк╡рлНркпрлБркВ ркЫрлЗ. </s>\n",
            "рккрк░ ркнрк╛рк░ ркорлВркХрк╛ркпрлЛ ркЕркирлЗ рк╕рлНркерк╛ркирк┐ркХ рк╕рлНркдрк░рлЗ рк╕рк╣ркХрк╛рк░ рк╡ркзрлНркпрлЛ. ркУркирк▓рк╛ркЗрки рккрлЛрк░рлНркЯрк▓ рккркг рк╢рк░рлВ ркХрк░рк╡рк╛ркорк╛ркВ ркЖрк╡рлНркпрлБркВ ркЫрлЗ. </s>\n",
            "рккрк░ ркнрк╛рк░ ркорлВркХрк╛ркпрлЛ ркЕркирлЗ рк╕рлНркерк╛ркирк┐ркХ рк╕рлНркдрк░рлЗ рк╕рк╣ркХрк╛рк░ рк╡ркзрлНркпрлЛ. ркУркирк▓рк╛ркЗрки рккрлЛрк░рлНркЯрк▓ рккркг рк╢рк░рлВ ркХрк░рк╡рк╛ркорк╛ркВ ркЖрк╡рлНркпрлБркВ ркЫрлЗ. </s>\n",
            "рккрк░ ркнрк╛рк░ ркорлВркХрк╛ркпрлЛ ркЕркирлЗ рк╕рлНркерк╛ркирк┐ркХ рк╕рлНркдрк░рлЗ рк╕рк╣ркХрк╛рк░ рк╡ркзрлНркпрлЛ. ркУркирк▓рк╛ркЗрки рккрлЛрк░рлНркЯрк▓ рккркг рк╢рк░рлВ ркХрк░рк╡рк╛ркорк╛ркВ ркЖрк╡рлНркпрлБркВ ркЫрлЗ. </s>\n",
            "рккрк░ ркнрк╛рк░ ркорлВркХрк╛ркпрлЛ ркЕркирлЗ рк╕рлНркерк╛ркирк┐ркХ рк╕рлНркдрк░рлЗ рк╕рк╣ркХрк╛рк░ рк╡ркзрлНркпрлЛ. ркУркирк▓рк╛ркЗрки рккрлЛрк░рлНркЯрк▓ рккркг рк╢рк░рлВ ркХрк░рк╡рк╛ркорк╛ркВ ркЖрк╡рлНркпрлБркВ ркЫрлЗ. </s>\n",
            "\n",
            "ЁЯФ╣ Katz Backoff - Beam Search\n",
            "рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░\n",
            "рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░\n",
            "рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░\n",
            "рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░\n",
            "рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░ рккрк░\n",
            "\n",
            "ЁЯФ╣ KneserтАУNey - Greedy\n",
            "601. ркмркирк╛рк╕ркХрк╛ркВркарк╛ркорк╛ркВ ркЖ ркорк╣рк┐ркирлЗ рккрк░рлНркпрк╛рк╡рк░ркг ркХрлНрк╖рлЗркдрлНрк░рлЗ ркЯрлНрк░рк╛рклрк┐ркХ рк╡рк┐ркнрк╛ркЧркП ркЦрлБрк▓рк╛рк╕рлЛ ркХрк░рлНркпрлЛ; рккркЫрлА 39 ркорлБркжрлНркжрк╛ркУ рккрк░ ркнрк╛рк░ ркорлВркХрк╛ркпрлЛ ркЕркирлЗ рк╕рлНркерк╛ркирк┐ркХ рк╕рлНркдрк░рлЗ рк╕рк╣ркХрк╛рк░\n",
            "601. ркмркирк╛рк╕ркХрк╛ркВркарк╛ркорк╛ркВ ркЖ ркорк╣рк┐ркирлЗ рккрк░рлНркпрк╛рк╡рк░ркг ркХрлНрк╖рлЗркдрлНрк░рлЗ ркЯрлНрк░рк╛рклрк┐ркХ рк╡рк┐ркнрк╛ркЧркП ркЦрлБрк▓рк╛рк╕рлЛ ркХрк░рлНркпрлЛ; рккркЫрлА 39 ркорлБркжрлНркжрк╛ркУ рккрк░ ркнрк╛рк░ ркорлВркХрк╛ркпрлЛ ркЕркирлЗ рк╕рлНркерк╛ркирк┐ркХ рк╕рлНркдрк░рлЗ рк╕рк╣ркХрк╛рк░\n",
            "601. ркмркирк╛рк╕ркХрк╛ркВркарк╛ркорк╛ркВ ркЖ ркорк╣рк┐ркирлЗ рккрк░рлНркпрк╛рк╡рк░ркг ркХрлНрк╖рлЗркдрлНрк░рлЗ ркЯрлНрк░рк╛рклрк┐ркХ рк╡рк┐ркнрк╛ркЧркП ркЦрлБрк▓рк╛рк╕рлЛ ркХрк░рлНркпрлЛ; рккркЫрлА 39 ркорлБркжрлНркжрк╛ркУ рккрк░ ркнрк╛рк░ ркорлВркХрк╛ркпрлЛ ркЕркирлЗ рк╕рлНркерк╛ркирк┐ркХ рк╕рлНркдрк░рлЗ рк╕рк╣ркХрк╛рк░\n",
            "601. ркмркирк╛рк╕ркХрк╛ркВркарк╛ркорк╛ркВ ркЖ ркорк╣рк┐ркирлЗ рккрк░рлНркпрк╛рк╡рк░ркг ркХрлНрк╖рлЗркдрлНрк░рлЗ ркЯрлНрк░рк╛рклрк┐ркХ рк╡рк┐ркнрк╛ркЧркП ркЦрлБрк▓рк╛рк╕рлЛ ркХрк░рлНркпрлЛ; рккркЫрлА 39 ркорлБркжрлНркжрк╛ркУ рккрк░ ркнрк╛рк░ ркорлВркХрк╛ркпрлЛ ркЕркирлЗ рк╕рлНркерк╛ркирк┐ркХ рк╕рлНркдрк░рлЗ рк╕рк╣ркХрк╛рк░\n",
            "601. ркмркирк╛рк╕ркХрк╛ркВркарк╛ркорк╛ркВ ркЖ ркорк╣рк┐ркирлЗ рккрк░рлНркпрк╛рк╡рк░ркг ркХрлНрк╖рлЗркдрлНрк░рлЗ ркЯрлНрк░рк╛рклрк┐ркХ рк╡рк┐ркнрк╛ркЧркП ркЦрлБрк▓рк╛рк╕рлЛ ркХрк░рлНркпрлЛ; рккркЫрлА 39 ркорлБркжрлНркжрк╛ркУ рккрк░ ркнрк╛рк░ ркорлВркХрк╛ркпрлЛ ркЕркирлЗ рк╕рлНркерк╛ркирк┐ркХ рк╕рлНркдрк░рлЗ рк╕рк╣ркХрк╛рк░\n",
            "\n",
            "ЁЯФ╣ KneserтАУNey - Beam Search\n",
            "601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601.\n",
            "601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601.\n",
            "601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601.\n",
            "601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601.\n",
            "601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601.\n"
          ]
        }
      ]
    }
  ]
}