{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pp5KX_pggmv",
        "outputId": "a3801bf8-e4e0-4b03-c71a-6e3b070831a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  1. Imports\n",
        "import nltk\n",
        "from collections import defaultdict, Counter\n",
        "import math, random\n",
        "\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrYLRMGNgiJ0",
        "outputId": "f4d026d1-5f1b-4d2e-d7af-f1eb336cf074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  2. Load and preprocess dataset\n",
        "\n",
        "file_path = \"Guj_3000.txt\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = f.read().splitlines()\n",
        "\n",
        "# Tokenize sentences (Gujarati text is tokenized by spaces)\n",
        "# Tokenize by splitting on spaces (works for Gujarati text)\n",
        "sentences = [sent.split() for sent in data]\n",
        "\n",
        "\n",
        "# Add start <s> and end </s> tokens for quadrigrams\n",
        "processed = []\n",
        "for sent in sentences:\n",
        "    processed.append([\"<s>\", \"<s>\", \"<s>\"] + sent + [\"</s>\"])\n",
        "\n",
        "print(\"Sample sentence tokens:\", processed[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESStdhjngmbB",
        "outputId": "9c28cfb9-d552-4dd3-f490-f2f024732526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample sentence tokens: ['<s>', '<s>', '<s>', '1.', 'ગાંધીનગરમાં', 'હાલમાં', 'રાજકારણ', 'ક્ષેત્રે', 'શાળા', 'વિકાસ', 'સમિતિએ', 'સ્થગિત', 'થયું;', 'તે', 'ઉપરાંત', '88', 'મુદ્દાઓ', 'પર', 'ભાર', 'મૂકાયો', 'અને', 'કારોબારમાં', 'વૃદ્ધિ', 'નોંધાઈ.', 'લક્ષ્યાંકો', 'આગામી', 'છ', 'મહિનામાં', 'પૂર્ણ', 'કરવાનો', 'ઉદ્દેશ', 'છે.', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  3. Build N-gram counts (up to 4-gram)\n",
        "from collections import Counter\n",
        "\n",
        "unigrams = Counter()\n",
        "bigrams = Counter()\n",
        "trigrams = Counter()\n",
        "quadrigrams = Counter()\n",
        "\n",
        "for sent in processed:\n",
        "    for i in range(len(sent)):\n",
        "        unigrams[tuple(sent[i:i+1])] += 1\n",
        "        if i < len(sent)-1:\n",
        "            bigrams[tuple(sent[i:i+2])] += 1\n",
        "        if i < len(sent)-2:\n",
        "            trigrams[tuple(sent[i:i+3])] += 1\n",
        "        if i < len(sent)-3:\n",
        "            quadrigrams[tuple(sent[i:i+4])] += 1\n",
        "\n",
        "print(\"Unigrams:\", len(unigrams))\n",
        "print(\"Quadrigrams:\", len(quadrigrams))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEA-pY_FguJI",
        "outputId": "40df0ec9-0083-4c75-cc1b-980e3b0aee36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams: 1370\n",
            "Quadrigrams: 10540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  4. Katz Backoff Implementation\n",
        "\n",
        "# For unseen higher n-grams, fall back to lower n-gram probability.\n",
        "\n",
        "def katz_backoff_prob(ngram, d=0.5):\n",
        "    \"\"\"\n",
        "    Compute Katz backoff probability for a given 4-gram.\n",
        "    \"\"\"\n",
        "    if quadrigrams[ngram] > 0:\n",
        "        return (quadrigrams[ngram] - d) / trigrams[ngram[:-1]]\n",
        "    elif trigrams[ngram[1:]] > 0:\n",
        "        return (trigrams[ngram[1:]] - d) / bigrams[ngram[1:-1]]\n",
        "    elif bigrams[ngram[2:]] > 0:\n",
        "        return (bigrams[ngram[2:]] - d) / unigrams[ngram[2:-1]]\n",
        "    else:\n",
        "        return unigrams[ngram[3:]] / sum(unigrams.values())\n"
      ],
      "metadata": {
        "id": "7Nrle1h3h_D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  5. Kneser–Ney Smoothing Implementation\n",
        "\n",
        "# Discounted continuation probability for unseen n-grams\n",
        "\n",
        "def kneser_ney_prob(ngram, d=0.75):\n",
        "    quad_count = quadrigrams[ngram]\n",
        "    tri_count = trigrams[ngram[:-1]]\n",
        "\n",
        "    if tri_count > 0:\n",
        "        prob = max(quad_count - d, 0) / tri_count\n",
        "        # continuation probability\n",
        "        continuation = len([1 for q in quadrigrams if q[1:] == ngram[1:]]) / len(quadrigrams)\n",
        "        prob += (d / tri_count) * continuation\n",
        "    else:\n",
        "        prob = unigrams[ngram[3:]] / sum(unigrams.values())\n",
        "\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "OMTGFZmniGd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📌 6. Sentence Generation (Greedy + Beam Search)\n",
        "VOCAB = list(set([w for s in processed for w in s]))\n",
        "\n",
        "def generate_sentence(model=\"katz\", max_len=20, method=\"greedy\", beam_size=20):\n",
        "    sent = [\"<s>\", \"<s>\", \"<s>\"]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        candidates = {}\n",
        "        for w in VOCAB:\n",
        "            ngram = tuple(sent[-3:] + [w])\n",
        "            if model == \"katz\":\n",
        "                prob = katz_backoff_prob(ngram)\n",
        "            else:\n",
        "                prob = kneser_ney_prob(ngram)\n",
        "            candidates[w] = prob\n",
        "\n",
        "        if method == \"greedy\":\n",
        "            next_word = max(candidates, key=candidates.get)\n",
        "            sent.append(next_word)\n",
        "            if next_word == \"</s>\":\n",
        "                break\n",
        "\n",
        "        elif method == \"beam\":\n",
        "            # Beam Search\n",
        "            beams = [[sent, 0.0]]\n",
        "            for _ in range(max_len):\n",
        "                new_beams = []\n",
        "                for seq, score in beams:\n",
        "                    for w in VOCAB:\n",
        "                        ngram = tuple(seq[-3:] + [w])\n",
        "                        if model == \"katz\":\n",
        "                            prob = katz_backoff_prob(ngram)\n",
        "                        else:\n",
        "                            prob = kneser_ney_prob(ngram)\n",
        "                        new_beams.append([seq+[w], score+math.log(prob+1e-10)])\n",
        "                # keep top k beams\n",
        "                beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n",
        "                if beams[0][0][-1] == \"</s>\":\n",
        "                    break\n",
        "            sent = beams[0][0]\n",
        "            break\n",
        "    return \" \".join(sent[3:])\n"
      ],
      "metadata": {
        "id": "QpBuAhEriOCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentence(model=\"katz\", max_len=20, method=\"greedy\", beam_size=20, top_k=50):\n",
        "    sent = [\"<s>\", \"<s>\", \"<s>\"]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        candidates = {}\n",
        "        for w in VOCAB:\n",
        "            if w == \"<s>\":\n",
        "                continue\n",
        "            ngram = tuple(sent[-3:] + [w])\n",
        "            if model == \"katz\":\n",
        "                prob = katz_backoff_prob(ngram)\n",
        "            else:\n",
        "                prob = kneser_ney_prob(ngram)\n",
        "            candidates[w] = prob\n",
        "\n",
        "        # keep only top_k candidates\n",
        "        candidates = dict(sorted(candidates.items(), key=lambda x: x[1], reverse=True)[:top_k])\n",
        "\n",
        "        if method == \"greedy\":\n",
        "            next_word = max(candidates, key=candidates.get)\n",
        "            sent.append(next_word)\n",
        "            if next_word == \"</s>\":\n",
        "                break\n",
        "\n",
        "        elif method == \"beam\":\n",
        "            beams = [[sent, 0.0]]\n",
        "            for _ in range(max_len):\n",
        "                new_beams = []\n",
        "                for seq, score in beams:\n",
        "                    for w, prob in candidates.items():  # 🚀 now only top_k words\n",
        "                        new_beams.append([seq+[w], score+math.log(prob+1e-10)])\n",
        "                beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n",
        "                if beams[0][0][-1] == \"</s>\":\n",
        "                    break\n",
        "            sent = beams[0][0]\n",
        "            break\n",
        "    return \" \".join(sent[3:])\n"
      ],
      "metadata": {
        "id": "mRlv5iSwsaYi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🔹 Katz Backoff - Greedy\")\n",
        "for i in range(5):\n",
        "    print(generate_sentence(model=\"katz\", method=\"greedy\"))\n",
        "\n",
        "print(\"\\n🔹 Katz Backoff - Beam Search\")\n",
        "for i in range(5):\n",
        "    print(generate_sentence(model=\"katz\", method=\"beam\"))\n",
        "\n",
        "print(\"\\n🔹 Kneser–Ney - Greedy\")\n",
        "for i in range(5):\n",
        "    print(generate_sentence(model=\"kn\", method=\"greedy\"))\n",
        "\n",
        "print(\"\\n🔹 Kneser–Ney - Beam Search\")\n",
        "for i in range(5):\n",
        "    print(generate_sentence(model=\"kn\", method=\"beam\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl7EhQVasbf_",
        "outputId": "95ef13e0-28c9-4d46-f075-0fad440227ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Katz Backoff - Greedy\n",
            "પર ભાર મૂકાયો અને સ્થાનિક સ્તરે સહકાર વધ્યો. ઓનલાઇન પોર્ટલ પણ શરૂ કરવામાં આવ્યું છે. </s>\n",
            "પર ભાર મૂકાયો અને સ્થાનિક સ્તરે સહકાર વધ્યો. ઓનલાઇન પોર્ટલ પણ શરૂ કરવામાં આવ્યું છે. </s>\n",
            "પર ભાર મૂકાયો અને સ્થાનિક સ્તરે સહકાર વધ્યો. ઓનલાઇન પોર્ટલ પણ શરૂ કરવામાં આવ્યું છે. </s>\n",
            "પર ભાર મૂકાયો અને સ્થાનિક સ્તરે સહકાર વધ્યો. ઓનલાઇન પોર્ટલ પણ શરૂ કરવામાં આવ્યું છે. </s>\n",
            "પર ભાર મૂકાયો અને સ્થાનિક સ્તરે સહકાર વધ્યો. ઓનલાઇન પોર્ટલ પણ શરૂ કરવામાં આવ્યું છે. </s>\n",
            "\n",
            "🔹 Katz Backoff - Beam Search\n",
            "પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર\n",
            "પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર\n",
            "પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર\n",
            "પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર\n",
            "પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર પર\n",
            "\n",
            "🔹 Kneser–Ney - Greedy\n",
            "601. બનાસકાંઠામાં આ મહિને પર્યાવરણ ક્ષેત્રે ટ્રાફિક વિભાગએ ખુલાસો કર્યો; પછી 39 મુદ્દાઓ પર ભાર મૂકાયો અને સ્થાનિક સ્તરે સહકાર\n",
            "601. બનાસકાંઠામાં આ મહિને પર્યાવરણ ક્ષેત્રે ટ્રાફિક વિભાગએ ખુલાસો કર્યો; પછી 39 મુદ્દાઓ પર ભાર મૂકાયો અને સ્થાનિક સ્તરે સહકાર\n",
            "601. બનાસકાંઠામાં આ મહિને પર્યાવરણ ક્ષેત્રે ટ્રાફિક વિભાગએ ખુલાસો કર્યો; પછી 39 મુદ્દાઓ પર ભાર મૂકાયો અને સ્થાનિક સ્તરે સહકાર\n",
            "601. બનાસકાંઠામાં આ મહિને પર્યાવરણ ક્ષેત્રે ટ્રાફિક વિભાગએ ખુલાસો કર્યો; પછી 39 મુદ્દાઓ પર ભાર મૂકાયો અને સ્થાનિક સ્તરે સહકાર\n",
            "601. બનાસકાંઠામાં આ મહિને પર્યાવરણ ક્ષેત્રે ટ્રાફિક વિભાગએ ખુલાસો કર્યો; પછી 39 મુદ્દાઓ પર ભાર મૂકાયો અને સ્થાનિક સ્તરે સહકાર\n",
            "\n",
            "🔹 Kneser–Ney - Beam Search\n",
            "601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601.\n",
            "601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601.\n",
            "601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601.\n",
            "601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601.\n",
            "601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601. 601.\n"
          ]
        }
      ]
    }
  ]
}