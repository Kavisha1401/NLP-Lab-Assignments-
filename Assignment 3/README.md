# 📘NLP Assignment 3

This directory contains solutions for NLP Assignment 1, which involves text preprocessing through custom tokenization and computation of corpus statistics on IndicCorpV2 and OSCAR datasets.


---

##  📂 Directory Structure
```
├── NLP-Assignment-3.pdf       # Assignment_3
├── Assignment3.ipynb          # Notebook with the solution
├── brown_text.txt             # Input dataset (text file)
├── README.md                  # Project documentation
```

---

## ⚙️ Requirements

Make sure you have the following installed:

- Python 3.8+  
- Jupyter Notebook or Google Colab  
- Required Python libraries:
  ```bash
  pip install numpy pandas matplotlib scikit-learn
  ```
  *(Add any extra libraries if the notebook imports them)*

---

## ▶️ How to Run

### 🔹 Option 1: Run in Google Colab
1. Open [Google Colab](https://colab.research.google.com/).  
2. Upload the notebook (`assignment.ipynb`) and dataset (`dataset.txt`).  
3. Update the dataset path inside the notebook if needed.  
4. Run all cells (`Runtime > Run All`).  

### 🔹 Option 2: Run Locally
1. Clone this repository:
   ```bash
   git clone https://github.com/your-username/your-repo.git
   cd your-repo
   ```
2. Launch Jupyter Notebook:
   ```bash
   jupyter notebook assignment.ipynb
   ```
3. Make sure `dataset.txt` is in the same folder as the notebook.  
4. Run the notebook cells step by step.

---

## 📊 Dataset

The dataset (`dataset.txt`) contains raw text input that the notebook processes for analysis. It includes various terms like `investigation`, `election`, `jury`, etc., which will be cleaned, tokenized, and used for further tasks.

---

## 📌 Output

The notebook demonstrates:
- Data preprocessing & text analysis  
- Frequency distribution and visualization  
- Any assignment-specific results as required  

---

##  Author
- **Your Name**  
- Roll No: *U23AI016*  
- Institute: *SVNIT*  


